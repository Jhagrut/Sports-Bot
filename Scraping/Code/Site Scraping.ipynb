{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7948d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07486a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function meant to quickly scrape information off of a standard Rotowire page.\n",
    "\n",
    "def scrape_twitter_links(page, xpath):\n",
    "    page.find_element_by_xpath(xpath).click()\n",
    "    soup = BeautifulSoup(page.page_source, 'html.parser')\n",
    "    hyperlinks = [subSoup.find_all('a') for subSoup in soup.find_all('div', {'class':'news-update is-injured'})]\n",
    "    hyperlinks = [links for nested_hyperlinks in hyperlinks for links in nested_hyperlinks]\n",
    "    hyperlinks = [subSoup['href'] for subSoup in hyperlinks if 'twitter' in subSoup['href']]\n",
    "    accounts = set([twitterLink.split('/')[3] for twitterLink in hyperlinks])\n",
    "    accounts = {accountNames + '\\n' for accountNames in accounts}\n",
    "    return accounts, hyperlinks\n",
    "\n",
    "# A helper function meant to be used with a list comprehension for NBC Sportsedge.\n",
    "\n",
    "def helper_function2(subSoup):\n",
    "    return subSoup.find('a', {'class': 'source-title'})['href']\n",
    "    \n",
    "def gather_twitter_accounts(hyperlink):\n",
    "    page = webdriver.Firefox()\n",
    "    page.get(hyperlink)\n",
    "    time.sleep(20)\n",
    "\n",
    "    soup = BeautifulSoup(page.page_source, 'html.parser')\n",
    "    page.close()\n",
    "\n",
    "    scraped_accounts = set([subSoup.getText().lstrip('@') + '\\n' \n",
    "                    for subSoup in soup.find_all('span', {'class':'username'})])\n",
    "    \n",
    "    file = open('accountList.txt', 'r')\n",
    "    valid_accounts = set(file.readlines())\n",
    "    file.close()\n",
    "    \n",
    "    with open('accountList.txt', 'w') as myfile:\n",
    "        \n",
    "        all_accounts = (scraped_accounts - broken_accounts - \n",
    "                       toBeFixed_accounts - valid_accounts).union(valid_accounts)\n",
    "        \n",
    "        for accounts in all_accounts:\n",
    "            myfile.write(accounts)\n",
    "    \n",
    "    print(len(all_accounts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b783e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2172\n"
     ]
    }
   ],
   "source": [
    "# Get accounts and injury tweets from NBC SportsEdge.\n",
    "\n",
    "page = webdriver.Firefox()\n",
    "page.get('https://www.nbcsportsedge.com/edge/baseball/mlb/player-news')\n",
    "time.sleep(10)\n",
    "\n",
    "soup = BeautifulSoup(page.page_source, 'html.parser')\n",
    "page.close()\n",
    "\n",
    "soup.find_all('div', {'class':'player-news-article__source'})\n",
    "links = [helper_function2(subSoup) for subSoup in soup.find_all('div', {'class':'player-news-article__source'})]\n",
    "filtered_links = [filtered_links for filtered_links in links if 'twitter' in filtered_links]\n",
    "accounts = set([links.split('/')[3] for links in filtered_links])\n",
    "accounts = {accountNames + '\\n' for accountNames in accounts}\n",
    "\n",
    "file = open('accountList.txt', 'r')\n",
    "text = file.readlines()\n",
    "file.close()\n",
    "\n",
    "with open('accountList.txt', 'w') as myfile:\n",
    "    for twitterAccounts in set(text).union(accounts):\n",
    "        myfile.write(twitterAccounts)\n",
    "        \n",
    "print(len(set(text).union(accounts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92957530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2172\n"
     ]
    }
   ],
   "source": [
    "# Get information off of Rotowire.\n",
    "\n",
    "page = webdriver.Firefox()\n",
    "page.get('https://www.rotowire.com/baseball/news.php?injuries=all')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "accounts, hyperlinks = scrape_twitter_links(page, '/html/body/div[1]/div/main/div[1]/div/div[2]/div/a[6]')\n",
    "time.sleep(2)\n",
    "accounts2, hyperlinks2 = scrape_twitter_links(page, '/html/body/div[1]/div/main/div[1]/div/div[2]/div/a[7]')\n",
    "\n",
    "accounts = accounts.union(accounts2)\n",
    "hyperlinks = hyperlinks + hyperlinks2\n",
    "\n",
    "page.close()\n",
    "\n",
    "file = open('accountList.txt', 'r')\n",
    "text = file.readlines()\n",
    "file.close()\n",
    "\n",
    "with open('accountList.txt', 'w') as myfile:\n",
    "    for twitterAccounts in set(text).union(accounts):\n",
    "        myfile.write(twitterAccounts)\n",
    "        \n",
    "print(len(set(text).union(accounts)))\n",
    "        \n",
    "with open('labeledTweets.txt', 'w') as myfile:\n",
    "    for labeledData in set([links + '\\n' for links in hyperlinks]):\n",
    "        myfile.write(labeledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae8668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2285\n",
      "2285\n",
      "2285\n",
      "2285\n",
      "2285\n",
      "2285\n",
      "2285\n",
      "2286\n",
      "2286\n",
      "2286\n",
      "2286\n",
      "2286\n",
      "2286\n",
      "2288\n",
      "2288\n",
      "2289\n",
      "2289\n",
      "2289\n",
      "2289\n",
      "2289\n",
      "2289\n",
      "2289\n",
      "2289\n",
      "2291\n",
      "2291\n",
      "2292\n",
      "2292\n",
      "2293\n",
      "2293\n",
      "2293\n",
      "2293\n",
      "2293\n",
      "2293\n",
      "2293\n",
      "2293\n",
      "2294\n",
      "2294\n",
      "2295\n",
      "2295\n",
      "2295\n",
      "2295\n",
      "2295\n",
      "2295\n",
      "2295\n",
      "2295\n",
      "2296\n",
      "2296\n",
      "2296\n",
      "2296\n",
      "2296\n",
      "2296\n",
      "2297\n",
      "2297\n",
      "2297\n",
      "2297\n",
      "2297\n",
      "2297\n",
      "2297\n",
      "2297\n",
      "2297\n",
      "2297\n",
      "2298\n",
      "2298\n",
      "2298\n",
      "2298\n",
      "2298\n",
      "2298\n",
      "2299\n",
      "2299\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2300\n",
      "2302\n",
      "2302\n",
      "2302\n",
      "2302\n",
      "2303\n",
      "2303\n",
      "2303\n",
      "2303\n",
      "2303\n",
      "2304\n",
      "2304\n",
      "2304\n",
      "2304\n",
      "2304\n",
      "2304\n",
      "2304\n",
      "2304\n",
      "2304\n",
      "2307\n",
      "2309\n",
      "2311\n",
      "2311\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2313\n",
      "2313\n",
      "2314\n",
      "2314\n",
      "2314\n",
      "2318\n",
      "2319\n",
      "2319\n",
      "2319\n",
      "2319\n",
      "2319\n",
      "2320\n",
      "2320\n",
      "2322\n",
      "2322\n",
      "2322\n",
      "2322\n",
      "2322\n",
      "2322\n",
      "2322\n",
      "2322\n",
      "2323\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2325\n",
      "2325\n",
      "2325\n",
      "2325\n",
      "2325\n",
      "2328\n",
      "2328\n",
      "2329\n",
      "2329\n",
      "2329\n",
      "2330\n",
      "2330\n",
      "2330\n",
      "2330\n",
      "2331\n",
      "2331\n",
      "2331\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2333\n",
      "2333\n",
      "2333\n",
      "2333\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2334\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2335\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2336\n",
      "2337\n",
      "2337\n",
      "2337\n",
      "2337\n",
      "2339\n",
      "2339\n",
      "2339\n",
      "2339\n",
      "2339\n",
      "2339\n",
      "2339\n",
      "2339\n",
      "2339\n",
      "2339\n",
      "2339\n",
      "2339\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2343\n",
      "2343\n",
      "2343\n",
      "2343\n",
      "2343\n",
      "2343\n",
      "2344\n",
      "2344\n",
      "2344\n",
      "2344\n",
      "2344\n",
      "2345\n",
      "2345\n",
      "2346\n",
      "2348\n",
      "2348\n",
      "2348\n",
      "2348\n",
      "2348\n",
      "2348\n",
      "2348\n",
      "2348\n",
      "2348\n",
      "2348\n",
      "2350\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2352\n",
      "2352\n",
      "2352\n",
      "2352\n",
      "2352\n",
      "2352\n",
      "2352\n",
      "2352\n",
      "2352\n",
      "2352\n",
      "2353\n",
      "2353\n",
      "2354\n",
      "2354\n",
      "2355\n",
      "2355\n",
      "2355\n",
      "2356\n",
      "2356\n",
      "2356\n",
      "2357\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2360\n",
      "2360\n",
      "2361\n",
      "2361\n",
      "2363\n",
      "2364\n",
      "2364\n",
      "2364\n",
      "2365\n",
      "2365\n",
      "2366\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2369\n",
      "2369\n",
      "2369\n",
      "2369\n",
      "2369\n",
      "2369\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2371\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2376\n",
      "2376\n",
      "2376\n",
      "2376\n",
      "2376\n",
      "2377\n",
      "2377\n",
      "2377\n",
      "2377\n",
      "2377\n",
      "2377\n",
      "2377\n",
      "2377\n",
      "2377\n",
      "2378\n",
      "2378\n",
      "2378\n",
      "2284\n",
      "2284\n",
      "2284\n",
      "2284\n",
      "2284\n",
      "2286\n",
      "2286\n",
      "2286\n",
      "2286\n",
      "2288\n",
      "2288\n",
      "2290\n",
      "2291\n",
      "2291\n",
      "2291\n",
      "2293\n",
      "2293\n",
      "2293\n",
      "2294\n",
      "2294\n",
      "2295\n",
      "2297\n",
      "2300\n",
      "2300\n",
      "2302\n",
      "2302\n",
      "2302\n",
      "2302\n",
      "2304\n",
      "2305\n",
      "2305\n",
      "2308\n",
      "2308\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-78a9d2c1640d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mschedule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file = open('brokenList.txt', 'r')\n",
    "broken_accounts = set(file.readlines())\n",
    "file.close()\n",
    "\n",
    "file = open('toBeFixed.txt', 'r')\n",
    "toBeFixed_accounts = set(file.readlines())\n",
    "file.close()\n",
    "\n",
    "schedule.every(3).minutes.do(gather_twitter_accounts, hyperlink='https://sportspyder.com/sports/mlb/tweets')\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1357305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
