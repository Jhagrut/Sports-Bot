{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2212\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "def scrape_twitter_links(page, xpath):\n",
    "    page.find_element_by_xpath(xpath).click()\n",
    "    soup = BeautifulSoup(page.page_source, 'html.parser')\n",
    "    hyperlinks = [subSoup.find_all('a') for subSoup in soup.find_all('div', {'class':'news-update is-injured'})]\n",
    "    hyperlinks = [links for nested_hyperlinks in hyperlinks for links in nested_hyperlinks]\n",
    "    hyperlinks = [subSoup['href'] for subSoup in hyperlinks if 'twitter' in subSoup['href']]\n",
    "    accounts = set([twitterLink.split('/')[3] for twitterLink in hyperlinks])\n",
    "    accounts = {accountNames + '\\n' for accountNames in accounts}\n",
    "    return accounts, hyperlinks\n",
    "\n",
    "page = webdriver.Firefox()\n",
    "page.get('https://www.rotowire.com/baseball/news.php?injuries=all')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "accounts, hyperlinks = scrape_twitter_links(page, '/html/body/div[1]/div/main/div[1]/div/div[2]/div/a[6]')\n",
    "time.sleep(2)\n",
    "accounts2, hyperlinks2 = scrape_twitter_links(page, '/html/body/div[1]/div/main/div[1]/div/div[2]/div/a[7]')\n",
    "\n",
    "accounts = accounts.union(accounts2)\n",
    "hyperlinks = hyperlinks + hyperlinks2\n",
    "\n",
    "page.close()\n",
    "\n",
    "file = open('accountList.txt', 'r')\n",
    "text = file.readlines()\n",
    "file.close()\n",
    "\n",
    "with open('accountList.txt', 'w') as myfile:\n",
    "    for twitterAccounts in set(text).union(accounts):\n",
    "        myfile.write(twitterAccounts)\n",
    "        \n",
    "print(len(set(text).union(accounts)))\n",
    "        \n",
    "with open('labeledTweets.txt', 'w') as myfile:\n",
    "    for labeledData in set([links + '\\n' for links in hyperlinks]):\n",
    "        myfile.write(labeledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
